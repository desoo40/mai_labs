{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Факультет \"Прикладная математика\" МАИ</h1>\n",
    "<h2>Курс \"Основы Python для анализа данных\"</h2>\n",
    "<h2>Артамонов Игорь Михайлович</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Занятие № 10. Деревья решений. k ближайших соседей.</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общение / вопросы по курсу\n",
    "\n",
    "Платформа для групповой работы Atlassian Confluence факультета \"Прикладная математика\"\n",
    "\n",
    "https://mai.moscow/display/PYTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Занятие № 10. Задачи машинного обучения. Деревья решений. k ближайших соседей.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## virtualenv + Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "<Ctrl> + <Alt> + T - новое окно терминала\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ conda -V\n",
    "\n",
    "$ conda update conda\n",
    "\n",
    "$ conda search \"^python$\"\n",
    "\n",
    "$ conda create -n yourenvname python=x.x anaconda\n",
    "\n",
    "$ source activate yourenvname\n",
    "\n",
    "$ jupyter notebook\n",
    "\n",
    "$ conda install -n yourenvname [package]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Деревья решений. k ближайших соседей. Кросс-энтропия.  Выбор моделей.</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задачи машинного обучения\n",
    "* регрессия\n",
    "* классификация\n",
    "* кластеризация\n",
    "\n",
    "#### Обычный порядок действий\n",
    "* получить \"сырые\" данные\n",
    "* понять, что они из себя представляют (см. EDA)\n",
    "* привести их в вид, пригодный для обучения модели\n",
    "* разбить тренировочную выборку на две: обучающую и проверочную (валидационную)\n",
    "* сравнить несколько алгоритмов машинного обучения, их настроек, чтобы получить наилучший результат для P на валидационной выборке\n",
    "* (_возможно_) повторить предыдущие три этапа несколько раз\n",
    "* обучить \"лучшую\" модель на всей тренировочной выборке\n",
    "* использовать модель для получения каких-то результатов\n",
    "* (_возможно_) провести дообучение модели с полученными свежими данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "from numpy.random import randn\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Машинное обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Определение.__ Мы считаем, что компьютерная программа __обучается__ при решении какой-то задачи из __класса  T__, если ее производительность, согласно __метрике P__, улучшается при накоплении __опыта E__.\n",
    "\n",
    "\n",
    "T. Mitchell \"Machine learning\", 1997\n",
    "https://www.cs.ubbcluj.ro/~gabis/ml/ml-books/McGrawHill%20-%20Machine%20Learning%20-Tom%20Mitchell.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* есть класс задач T\n",
    "* есть метрика производительности P\n",
    "* есть понятие опыта E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры задач:\n",
    "* задача распзнавания изображений\n",
    "* задача классификации новых объектов\n",
    "* задача обучения игре"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=green>ВОПРОС</font>\n",
    "\n",
    "Где здесь __T, P__ и  __E__?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритмы машинного обучения делятся на:\n",
    "* обучающиеся с учителем (__supervised__ learning).\n",
    "* обучающиеся без учителя (__unsupervised__ learning).<br><br>\n",
    "\n",
    "Общее в этих задачах - наличие некоторой выборки данных (информации об объектах), \n",
    "которую называют набором признаков (__object features__). При обучении без учителя\n",
    "никакой дополнительной информации, связанной с __каждым объектом__ нет.\n",
    "\n",
    "В случе обучения __с учителем__ с каждым из объектов связывается дополнительный\n",
    "целевой признак. Это то, что хотелось бы прогнозировать для прочих объектов, \n",
    "не из обучающей выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основными задачами в машинном обучении являются:\n",
    "* Обучение с учителем:\n",
    "    - __регрессия__ – прогнозирование количественного признака объекта на основании прочих его признаков\n",
    "    - __классификация__ – отнесение объекта к одной из категорий на основании его признаков<br><br>\n",
    "* Обучение без учителя:\n",
    "    - __кластеризация__ – разбиение множества объектов на группы на основании анализа признаков этих объектов так, чтобы внутри групп объекты были, в некотором смысле, более \"близкими\" между собой, а вне одной группы – менее \"близкими\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Минимальный путь машинного обучения выглядит так:\n",
    "* обучиться на обучающей выборке (получить опыт E) так, чтобы на этой выборке метрика P \n",
    "достигла своего экстремума\n",
    "* применить полученный опыт E к новым данным (данным за пределами обучающей выборки), чтобы сделать что-то хорошее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более адекватный (и реалистичный) путь машинного обучения выглядит так:\n",
    "* определить цель обучения (business goal)\n",
    "* определить критерий оценки (метрика, preformance measure)\n",
    "* получить \"сырые\" данные\n",
    "* понять, что они из себя представляют (см. EDA)\n",
    "* привести их в вид, пригодный для обучения модели\n",
    "* разбить тренировочную выборку на две: обучающую и проверочную (валидационную)\n",
    "* сравнить несколько алгоритмов машинного обучения, их настроек, чтобы получить наилучший результат для P на валидационной выборке\n",
    "* (_возможно_) повторить предыдущие три этапа несколько раз\n",
    "* обучить \"лучшую\" модель на всей тренировочной выборке\n",
    "* использовать модель для получения каких-то результатов\n",
    "* (_возможно_) провести дообучение модели с полученными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* одна из основных бибилотек, используемая при машинном обучении\n",
    "* содержит много качественных алгоритмов и хорошую документацию\n",
    "* имеет _типовую_ логику применения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* данные состоят из тренировочных и тестовых данных\n",
    "* Делим тренировочную выборку на входные и выходные переменные\n",
    "* Заполняем пропущенные данные (см. предыдущее занятие № 9)\n",
    "* Фильтрация пропущенных данных\n",
    "* Проверяем, остались ли не заполненные данные?\n",
    "* Выполняем преобразование данных (смещенные распределения, логарифмирование и т.д.)\n",
    "* Создаем признаки:\n",
    "    * составные\n",
    "    * бинарные\n",
    "    * категориальные\n",
    "* Создаем классификатор / регрессор\n",
    "* Учим классификатор / регрессор на тренировочных данных с валидационными выборками\n",
    "* Проверяем обучение классификатора на тестовой выборке\n",
    "* Повторяем ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики для регрессии. MSE / MAE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Среднеквадратичное отклонение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ RMSE(X, h) = \\sqrt { \\frac{1}{n}\\sum_{i=1}^{n} (h(x_i) - y_i)^2 } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Среднее абсолютное отклонение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ MAE(X, h) = \\sqrt { \\frac{1}{n}\\sum_{i=1}^{n} \\lvert h(x_i) - y_i \\rvert  } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики для классификации. Кросс-энтропия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Энтропия__ — это то, как много информации нам __не__ известно о системе. Это не __свойство системы__, это свойство __знания__ о системе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Степень удивления\n",
    "Степень, насколько мы удивлены, увидев результат\n",
    "$$ s = \\log \\frac{1}{p_i} $$\n",
    "где $p_i$ - вероятность $i$-го исхода<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Энтропия\n",
    "Взвешенное среднее \"удивления\" от индивидуальных исходов\n",
    "$$ e = \\sum_{i=1}^{n} p_i * \\log \\frac{1}{p_i} = - \\sum_{i=1}^{n} p_i * \\log p_i $$\n",
    "Если использовать основание логарифма, равное 2:\n",
    "$$ e = - \\sum_{i=1}^{n} p_i * \\log_2 p_i $$\n",
    "то эта формула также называется \"информационной энтропией\" или \"энтропией Шеннона\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Кросс-энтропия\n",
    "Взвешенное среднее \"удивления\" от индивидуальных исходов, когда вероятность остается $p_i$, однако\n",
    "наблюдатель считает, что она равна $q_i$\n",
    "$$ e = \\sum_{i=1}^{n} p_i * log \\frac{1}{q_i} = - \\sum_{i=1}^{n} p_i * log \\ q_i$$\n",
    "Кросс-энтропия всегда __больше__ чем энтропия, за исключением случая, когда наблюдатель точно знает реальное распределение (тода $p_i = q_i$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images10/cross-ent-01.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* фиолетовый \"столбик\" - площадь под синей кривой\n",
    "* синяя кривая - кросс-энтропия\n",
    "* красная кривая - реальное распределение вероятностей\n",
    "* оранжевая кривая - ожидаемое распределение вероятностей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для случая 2-х исходов (бинарная классификация - \"да/нет\", \"истинно/ложно\")\n",
    "$$ e = \\sum_{i=0}^{1} p_i * log \\frac{1}{q_i} = \n",
    "   p_0 log \\frac{1}{q_0} + p_1 log \\frac{1}{q_1} = \n",
    "   - p_0 log \\ q_0 - (1-p_0) log \\ 1-q_0 \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">ЗАДАНИЕ</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте:\n",
    "* график, аналогичный приведенному\n",
    "* график изменния кросс-энтропии для двух нормальных распределений с  $\\sigma = 1$ в зависимости от расстояния между их матожиданиями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Неопределенность Джини (Gini impurity)\n",
    "$$ G = 1 - \\sum_{k} (p_k)^2$$\n",
    "Максимизацию этого критерия можно интерпретировать как максимизацию числа пар\n",
    "объектов одного класса, оказавшихся в одном поддереве"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кросс-энтропия и деревья решений\n",
    "Пример из  https://habr.com/post/171759/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что нам надо найти правила разбиения набора данных таким образом, \n",
    "чтобы среднее значение энтропии уменьшалось. Это означает, что наше знание о системе __растет__ и этот процесс можно рассматривать как _производство информации_ ()\n",
    "\n",
    "Если мы разбили исходный набор данных на две части по некому предикату, то можно рассчитать энтропию каждого подмножества. Если после среднее значение энтропии окажется меньшим чем энтропия исходного множества, значит предикат содержит некую обобщающую информацию о данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images10/cross-ent-02.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы ограничены простыми предикатами, то одного условия будет недостаточно. Поэтому, \n",
    "если повторять эту процедуру рекурсивно для каждого подмножества, мы получим древовидный набор условий, \n",
    "который назвается __деревом принятия решений__ (decision tree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images10/cross-ent-03.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* листьями дерева принятия решений являются _классы_\n",
    "* классификация происходит путем спуска вниз по дереву\n",
    "* процесс спуска можно трактовать как процесс _объяснения_, почему объект отнесен к тому или иному классу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=green>ВОПРОС</font>\n",
    "* Можно ли использовать дерево для регрессии?\n",
    "* Можно ли использовать дерево для кластеризации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры класса __sklearn.tree._DecisionTreeClassifier___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __criterion__ (опционально):\n",
    "    - функция оценки качества разбиеная (”gini” или \"entropy\")\n",
    "* __splitter__ (опционально):\n",
    "    - стратегия, используемая для разбиения в каждом узле (“best” - лучший вариент, “random” - случайное разбиение).\n",
    "* __max_depth__ (опционально):\n",
    "    - максимальная глубина дерева\n",
    "* __min_samples_split__  (опционально):\n",
    "    - минимальное количество примеров, требуемое для разбиения внутреннего узла.\n",
    "* __random_state__  (опционально):\n",
    "    - начальное значение (seed) для генератора случайных чисел"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры дерева\n",
    "\n",
    "## <font color=green>ВОПРОС</font>\n",
    "* Зачем ограничивать глубину дерева?\n",
    "* Зачем ограничивать минимальное количество записей в узле"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда деревья строятся до максимальной глубины:\n",
    "* композиция деревьев (\"лес\", в том числе - случайный (_random forest_)) - усреднение ответов\n",
    "* стрижка дерева - отсечение вершин за счет сравнения качества дерева с данным разибением и без него"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images10/dt_iterations.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images10/reg_dt_path.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод ближайших соседей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В основе - выбор ближайших, по некоторому расстоянию, соседей. Предполагается, что каковы ближайшие соседи, \n",
    "таков и данный элемент. Метод часто используется как базовый или для построения мета-признаков \n",
    "(подается на вход другим моделям)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм:\n",
    "* вычислить попарное расстояние между объектами обучающей выборки\n",
    "* выбрать $k$ элементов обучающей выборки, расстояние до которых минимально\n",
    "* класс объекта - это класс, наиболее часто встречающийся среди $k$ ближайших соседей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры метода ближайших соседей\n",
    "* число соседей ($k$)\n",
    "* метрика расстояний между объектами (евклидово расстояние, косинусное расстояние, метрика Хэмминга и др.)\n",
    "* веса соседей (часто зависят от расстояний)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры класса __sklearn.neighbors._KNeighborsClassifier___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __weights__\n",
    "    - _\"uniform\"_ - все веса равны\n",
    "    - _\"distance\"_ - вес обратно пропорционален расстоянию до тестового примера\n",
    "    - _другая_ определенная пользователем функция\n",
    "* __algorithm__ (опционально):\n",
    "    - _\"auto\"_ - выбирается автоматически\n",
    "    - _\"brute\"_ - считаются полным перебором обучающей выборки\n",
    "    - _\"ball__tree\"_ / KD_tree - расстояния хранятся в дереве, что ускоряет поиск соседей\n",
    "* __leaf_size__ (опционально):\n",
    "    - порог переключения на полный перебор в случае выбора BallTree или KDTree для нахождения соседей\n",
    "* __metric__: \n",
    "    - _\"minkowski\"_, _\"manhattan\"_, _\"euclidean\"_, _\"chebyshev\"_ ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная задача обучаемых алгоритмов - способность работать на новых данных. \n",
    "Для проверки обобщающей способности модели наиболее часто используются разбиение тренировочной выборки на две\n",
    "части: собственно тренировочная (в которую попадает обычно 60-80% от всей выборки) и отложенная \n",
    "(проверочная, валидационная). \n",
    "Это разбиение может быть сделано несколькими способами:\n",
    "* \"вырезаем\" непрерывную часть выборки нужного размера, остальные элементы используются для обучения\n",
    "* выбираем некоторое количество элементов случайным образом и используем остальные для обучения\n",
    "* делаем несколько последовательных выборок (непрерывных или случайных), чтобы улучшить нашу оценку\n",
    "моделей за счет осреднения (кросс-валидация - _cross validation_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кросс-валидация (K-Fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images10/cross-val-02.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "используется для:\n",
    "* выбора модели\n",
    "* настройки параметров модели\n",
    "* оценки полезности признаков\n",
    "Основная проблема - высокая \"цена\" на больших выборках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первые два способа реализуются __sklearn.model_selection.train_test_split__, вторые - __model_selection.KFold__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сохранения распределения целевых признаков по классам используются StratifiedKFold, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение на базе данных рукописных цифр (MINST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data = load_digits()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X[0,:].reshape([8,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 4, sharey=True, figsize=(16,6))\n",
    "for i in range(4):\n",
    "    axes[i].imshow(X[i,:].reshape([8,8]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.3, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=5, random_state=17)\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pred = tree.predict(X_holdout)\n",
    "knn_pred = knn.predict(X_holdout)\n",
    "accuracy_score(y_holdout, knn_pred), accuracy_score(y_holdout, tree_pred) # (0.97, 0.666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_params = {'max_depth': [1, 2, 3, 5, 10, 20, 25, 30, 40, 50, 64],\n",
    "'max_features': [1, 2, 3, 5, 10, 20 ,30, 50, 64]}\n",
    "\n",
    "tree_grid = GridSearchCV(tree, tree_params, cv=5, n_jobs=-1, verbose=True, iid=None)\n",
    "\n",
    "tree_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid.best_params_, tree_grid.best_score_ # ({'max_depth': 20, 'max_features': 64}, 0.844)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(KNeighborsClassifier(n_neighbors=1), X_train, y_train, cv=5)) # 0.987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(RandomForestClassifier(n_estimators=20, random_state=17), X_train, y_train, cv=5)) # 0.959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(GradientBoostingClassifier(n_estimators=200, random_state=17), X_train, y_train, cv=5)) # 0.953"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед домашним заданием __очень__ рекомендуется:\n",
    "* перечитать https://habr.com/company/ods/blog/322534/\n",
    "* сделать открытое задание к нему (__сдается на занятии!__ не присылать!):\n",
    "http://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_russian/assignments_demo/assignment03_decision_trees.ipynb\n",
    "(+5 баллов, как и ДЗ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">ЗАДАНИЕ</font>\n",
    "\n",
    "* Загрузите датасет https://archive.ics.uci.edu/ml/datasets/Adult\n",
    "* Применити к нему методы kNN, случайное дерево и ансамбль случайных деревьев\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание (6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общая схема алгоритма:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def build(L):\n",
    "    create node t\n",
    "    if the stopping criterion is True:\n",
    "        assign a predictive model to t\n",
    "    else:\n",
    "        Find the best binary split L = L_left + L_right\n",
    "        t.left = build(L_left)\n",
    "        t.right = build(L_right)\n",
    "    return t  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    \"\"\"\n",
    "    В качестве функции потерь используйте логистическую функцию потерь, или же функцию потерь\n",
    "    для кросс-энтропии sklearn.metrics.log_loss\n",
    "    \"\"\"\n",
    "    def __init__(self, max_tree_depth, min_node_records):\n",
    "        self.max_tree_depth = max_tree_depth\n",
    "        self.min_node_records = min_node_records\n",
    "        self.regression = regression\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X - матрица входным параметров n x m\n",
    "        y - вектор исходов n, каждое из которых имеет одно из ограниченного множества значений,\n",
    "            определяющего класс\n",
    "            \n",
    "        Предполагается, что для элементов матрицы можно выполнять операции сравнения (<,=,>)\n",
    "\n",
    "        После выполнения данной функции дерево должно быть обученным и способным предсказывать\n",
    "        значение\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def split(self, X, y):\n",
    "        \"\"\"\n",
    "        Внутренняя функция. Разбивает матрицу на 2 смежные части, максимизируя критерий.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Выводит вектор предсказаний для заданной матрицы X\n",
    "        \"\"\"\n",
    "\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Экзаменационные вопросы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* метрики, применямемые в классификации\n",
    "* кросс-энтропия и неопределенность Джини\n",
    "* принципы построения деревьев выбора\n",
    "* метод k ближайших средних (kNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
