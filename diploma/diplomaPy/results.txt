C:\Program Files\Python36\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
dp.py:63: UserWarning: loadtxt: Empty input file: "<_io.TextIOWrapper name='train.csv' mode='r' encoding='cp1251'>"
  predict_data = np.loadtxt(train, delimiter=';')
              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00   4450191
         1.0       0.46      0.40      0.43      3643

   micro avg       1.00      1.00      1.00   4453834
   macro avg       0.73      0.70      0.71   4453834
weighted avg       1.00      1.00      1.00   4453834

[[4448523    1668]
 [   2197    1446]]
PS F:\projects\other\diplomapy>
PS F:\projects\other\diplomapy> py dp.py
C:\Program Files\Python36\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
dp.py:63: UserWarning: loadtxt: Empty input file: "<_io.TextIOWrapper name='train.csv' mode='r' encoding='cp1251'>"
  predict_data = np.loadtxt(train, delimiter=';')
              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00   4450191
         1.0       0.46      0.40      0.43      3643

   micro avg       1.00      1.00      1.00   4453834
   macro avg       0.73      0.70      0.71   4453834
weighted avg       1.00      1.00      1.00   4453834

[[4448523    1668]
 [   2197    1446]]
PS F:\projects\other\diplomapy> py dp.py
C:\Program Files\Python36\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00   1904216
         1.0       1.00      0.15      0.26      4570

   micro avg       1.00      1.00      1.00   1908786
   macro avg       1.00      0.58      0.63   1908786
weighted avg       1.00      1.00      1.00   1908786

[[1904216       0]
 [   3882     688]]
PS F:\projects\other\diplomapy> py dp.py
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00   1904216
         1.0       0.86      0.79      0.83      4570

   micro avg       1.00      1.00      1.00   1908786
   macro avg       0.93      0.90      0.91   1908786
weighted avg       1.00      1.00      1.00   1908786

[[1903648     568]
 [    956    3614]]
PS F:\projects\other\diplomapy> py dp.py
C:\Program Files\Python36\lib\site-packages\sklearn\ensemble\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
  "10 in version 0.20 to 100 in 0.22.", FutureWarning)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00   1904216
         1.0       0.97      0.70      0.82      4570

   micro avg       1.00      1.00      1.00   1908786
   macro avg       0.99      0.85      0.91   1908786
weighted avg       1.00      1.00      1.00   1908786

[[1904129      87]
 [   1351    3219]]
PS F:\projects\other\diplomapy> py dp.py
GaussianNB(priors=None, var_smoothing=1e-09)
              precision    recall  f1-score   support

         0.0       1.00      0.99      1.00   1904216
         1.0       0.07      0.17      0.10      4570

   micro avg       0.99      0.99      0.99   1908786
   macro avg       0.53      0.58      0.55   1908786
weighted avg       1.00      0.99      0.99   1908786

[[1893619   10597]
 [   3803     767]]C:\Program Files\Python36\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
dp.py:63: UserWarning: loadtxt: Empty input file: "<_io.TextIOWrapper name='train.csv' mode='r' encoding='cp1251'>"
  predict_data = np.loadtxt(train, delimiter=';')
              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00   4450191
         1.0       0.46      0.40      0.43      3643

   micro avg       1.00      1.00      1.00   4453834
   macro avg       0.73      0.70      0.71   4453834
weighted avg       1.00      1.00      1.00   4453834

[[4448523    1668]
 [   2197    1446]]
PS F:\projects\other\diplomapy>
PS F:\projects\other\diplomapy> py dp.py
C:\Program Files\Python36\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
dp.py:63: UserWarning: loadtxt: Empty input file: "<_io.TextIOWrapper name='train.csv' mode='r' encoding='cp1251'>"
  predict_data = np.loadtxt(train, delimiter=';')
              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00   4450191
         1.0       0.46      0.40      0.43      3643

   micro avg       1.00      1.00      1.00   4453834
   macro avg       0.73      0.70      0.71   4453834
weighted avg       1.00      1.00      1.00   4453834

[[4448523    1668]
 [   2197    1446]]
PS F:\projects\other\diplomapy> py dp.py
C:\Program Files\Python36\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00   1904216
         1.0       1.00      0.15      0.26      4570

   micro avg       1.00      1.00      1.00   1908786
   macro avg       1.00      0.58      0.63   1908786
weighted avg       1.00      1.00      1.00   1908786

[[1904216       0]
 [   3882     688]]
PS F:\projects\other\diplomapy> py dp.py
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00   1904216
         1.0       0.86      0.79      0.83      4570

   micro avg       1.00      1.00      1.00   1908786
   macro avg       0.93      0.90      0.91   1908786
weighted avg       1.00      1.00      1.00   1908786

[[1903648     568]
 [    956    3614]]
PS F:\projects\other\diplomapy> py dp.py
C:\Program Files\Python36\lib\site-packages\sklearn\ensemble\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
  "10 in version 0.20 to 100 in 0.22.", FutureWarning)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00   1904216
         1.0       0.97      0.70      0.82      4570

   micro avg       1.00      1.00      1.00   1908786
   macro avg       0.99      0.85      0.91   1908786
weighted avg       1.00      1.00      1.00   1908786

[[1904129      87]
 [   1351    3219]]
PS F:\projects\other\diplomapy> py dp.py
GaussianNB(priors=None, var_smoothing=1e-09)
              precision    recall  f1-score   support

         0.0       1.00      0.99      1.00   1904216
         1.0       0.07      0.17      0.10      4570

   micro avg       0.99      0.99      0.99   1908786
   macro avg       0.53      0.58      0.55   1908786
weighted avg       1.00      0.99      0.99   1908786

[[1893619   10597]
 [   3803     767]]